{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Cosima10/master-thesis/blob/main/keyword_scraper_on_news_sites.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "LatzIlSM-6vg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d495d0b3-bd20-4e27-a5dd-47b3163712dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "!pip install selenium\n",
        "!apt-get update # to update ubuntu to correctly run apt install\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
        "import sys\n",
        "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n",
        "from selenium import webdriver\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "wd = webdriver.Chrome('chromedriver',chrome_options=chrome_options)\n",
        "import time\n",
        "driver = wd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmjYjDb1_yAr",
        "outputId": "0ba702bc-5011-4afd-a287-c6a29cab641d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: selenium in /usr/local/lib/python3.7/dist-packages (4.1.3)\n",
            "Requirement already satisfied: urllib3[secure,socks]~=1.26 in /usr/local/lib/python3.7/dist-packages (from selenium) (1.26.9)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.7/dist-packages (from selenium) (0.9.2)\n",
            "Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.7/dist-packages (from selenium) (0.20.0)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (1.1.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (1.2.0)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (21.4.0)\n",
            "Requirement already satisfied: async-generator>=1.9 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (1.10)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.10)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.7/dist-packages (from trio-websocket~=0.9->selenium) (1.1.0)\n",
            "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium) (2021.10.8)\n",
            "Requirement already satisfied: cryptography>=1.3.4 in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium) (36.0.2)\n",
            "Requirement already satisfied: pyOpenSSL>=0.14 in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium) (22.0.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium) (2.21)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.13.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from h11<1,>=0.9.0->wsproto>=0.14->trio-websocket~=0.9->selenium) (4.1.1)\n",
            "Ign:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Ign:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:6 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:12 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Hit:13 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:14 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:16 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,950 kB]\n",
            "Get:17 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [998 kB]\n",
            "Fetched 3,216 kB in 7s (479 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "chromium-chromedriver is already the newest version (99.0.4844.84-0ubuntu0.18.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 52 not upgraded.\n",
            "cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: DeprecationWarning: use options instead of chrome_options\n",
            "  from ipykernel import kernelapp as app\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# initialising string\n",
        "def hapusspecialcharacter(ini_string):\n",
        "    getVals = list([val for val in ini_string\n",
        "                   if val.isalpha() or val.isnumeric()or val == \" \"])\n",
        "    result = \"\".join(getVals)\n",
        "    return result\n",
        "\n",
        "def unique(list1):\n",
        "    unique_list = []\n",
        "    for x in list1:\n",
        "        if x not in unique_list:\n",
        "            unique_list.append(x)\n",
        "    return(unique_list)\n",
        "\n",
        "def years_check(year, df):\n",
        "    number_of_news_in_2022 = len(df[df['date'].str.contains(str(year))])\n",
        "    return number_of_news_in_2022\n",
        "\n",
        "path_source = \"/content/drive/MyDrive/scraper/df link.xlsx\"\n",
        "df_link = pd.read_excel(path_source)"
      ],
      "metadata": {
        "id": "3hs8sLae-ASO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# saving the results \n",
        "path_output = \"/content/drive/MyDrive/scraper/result/\""
      ],
      "metadata": {
        "id": "mbhXFCMoDfhl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GERMANY\n",
        "\n",
        "def germany1ntv(keyword):\n",
        "  news_links = []\n",
        "  dates = []\n",
        "  iprocess = 7\n",
        "  for ipage in list(range(21))[1:]:\n",
        "    wd.get(\"https://www.n-tv.de/suche/?q=keyword&at=all&page=\".replace(\"keyword\",keyword)+str(ipage))\n",
        "    print(str(ipage))\n",
        "    content = driver.page_source.encode('utf-8').strip()\n",
        "    soup = BeautifulSoup(content)\n",
        "    b = soup.find_all(\"article\",\"teaser teaser--inline \")\n",
        "    for i in b:\n",
        "      news_links.append(\"\"+i.find(\"a\").get(\"href\"))\n",
        "      dates.append(i.find(\"span\",\"teaser__date\").get_text().replace(\"\\n                        \",\"\").replace(\"\\n                      \",\"\"))\n",
        "  kamus = {\"news link\":news_links, \"date\":dates}\n",
        "  df = pd.DataFrame(kamus)\n",
        "  file_name = path_output+df_link['country'][iprocess]+\" \"+str(df_link['number'][iprocess])+\" \"+df_link['link'][iprocess].replace(\"https://\",\"\").replace(\"/\",\"\").replace(\".\",\" \")+\".xlsx\"\n",
        "  df.to_excel(file_name, index=False)\n",
        "  yearList = []\n",
        "  counterList = []\n",
        "  for i in range(2023)[-6:]:\n",
        "    yearList.append(i)\n",
        "    counterList.append(years_check(i, df))\n",
        "  file_nameCek = path_output+\"result \"+df_link['country'][iprocess]+\" \"+str(df_link['number'][iprocess])+\" \"+df_link['link'][iprocess].replace(\"https://\",\"\").replace(\"/\",\"\").replace(\".\",\" \")+\".xlsx\"\n",
        "  kamusCek = {\"year\": yearList, \"Number of Related News\": counterList}\n",
        "  dfCek = pd.DataFrame(kamusCek)\n",
        "  dfCek.to_excel(file_nameCek, index=False)\n",
        "  return dfCek\n",
        "\n",
        "def germany3dw(keyword):\n",
        "  news_links = []\n",
        "  dates = []\n",
        "  iprocess = 9\n",
        "  wd.get(\"https://www.dw.com/search/?languageCode=en&item=keyword&searchNavigationId=9097&sort=DATE&resultsCounter=10000\".replace(\"keyword\",keyword))\n",
        "  content = driver.page_source.encode('utf-8').strip()\n",
        "  soup = BeautifulSoup(content)\n",
        "  b = soup.find_all(\"div\",\"searchResult\")\n",
        "  for i in b:\n",
        "    news_links.append(\"\"+i.find(\"a\").get(\"href\"))\n",
        "    dates.append(i.find(\"span\",\"date\").get_text().replace(\"\\n                        \",\"\").replace(\"\\n                      \",\"\"))\n",
        "  kamus = {\"news link\":news_links, \"date\":dates}\n",
        "  df = pd.DataFrame(kamus)\n",
        "  file_name = path_output+df_link['country'][iprocess]+\" \"+str(df_link['number'][iprocess])+\" \"+df_link['link'][iprocess].replace(\"https://\",\"\").replace(\"/\",\"\").replace(\".\",\" \")+\".xlsx\"\n",
        "  df.to_excel(file_name, index=False)\n",
        "  yearList = []\n",
        "  counterList = []\n",
        "  for i in range(2023)[-6:]:\n",
        "    yearList.append(i)\n",
        "    counterList.append(years_check(i, df))\n",
        "  file_nameCek = path_output+\"result \"+df_link['country'][iprocess]+\" \"+str(df_link['number'][iprocess])+\" \"+df_link['link'][iprocess].replace(\"https://\",\"\").replace(\"/\",\"\").replace(\".\",\" \")+\".xlsx\"\n",
        "  kamusCek = {\"year\": yearList, \"Number of Related News\": counterList}\n",
        "  dfCek = pd.DataFrame(kamusCek)\n",
        "  dfCek.to_excel(file_nameCek, index=False)\n",
        "  return dfCek\n",
        "\n",
        "def germany4faz(keyword):\n",
        "  news_links = []\n",
        "  dates = []\n",
        "  iprocess = 10\n",
        "  for ipage in list(range(21))[1:]:\n",
        "    wd.get(\"https://www.faz.net/suche/sipage.html?ct=article&ct=audio&ct=blog&ct=gallery&ct=infografik&ct=storytelling&ct=video&&query=keyword#listPagination\".replace(\"keyword\",keyword).replace(\"ipage\", str(ipage)))\n",
        "    print(str(ipage))\n",
        "    content = driver.page_source.encode('utf-8').strip()\n",
        "    soup = BeautifulSoup(content)\n",
        "    b = soup.find_all(\"li\",\"lst-Teaser_Item\")\n",
        "    for i in b:\n",
        "      news_links.append(\"\"+i.find(\"a\").get(\"href\"))\n",
        "      dates.append(i.find(\"time\").get_text().replace(\"\\n                        \",\"\").replace(\"\\n                      \",\"\"))\n",
        "  kamus = {\"news link\":news_links, \"date\":dates}\n",
        "  df = pd.DataFrame(kamus)\n",
        "  file_name = path_output+df_link['country'][iprocess]+\" \"+str(df_link['number'][iprocess])+\" \"+df_link['link'][iprocess].replace(\"https://\",\"\").replace(\"/\",\"\").replace(\".\",\" \")+\".xlsx\"\n",
        "  df.to_excel(file_name, index=False)\n",
        "  yearList = []\n",
        "  counterList = []\n",
        "  for i in range(2023)[-6:]:\n",
        "    yearList.append(i)\n",
        "    counterList.append(years_check(i, df))\n",
        "  file_nameCek = path_output+\"result \"+df_link['country'][iprocess]+\" \"+str(df_link['number'][iprocess])+\" \"+df_link['link'][iprocess].replace(\"https://\",\"\").replace(\"/\",\"\").replace(\".\",\" \")+\".xlsx\"\n",
        "  kamusCek = {\"year\": yearList, \"Number of Related News\": counterList}\n",
        "  dfCek = pd.DataFrame(kamusCek)\n",
        "  dfCek.to_excel(file_nameCek, index=False)\n",
        "  return dfCek"
      ],
      "metadata": {
        "id": "qYI0RphG-AMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DENMARK \n",
        "\n",
        "def denmark1information(keyword):\n",
        "  news_links = []\n",
        "  dates = []\n",
        "  iprocess = 0\n",
        "  for ipage in list(range(21))[1:]:\n",
        "    wd.get(\"https://www.information.dk/search/site/youtue?page=\".replace(\"keyword\",keyword)+str(ipage))\n",
        "    print(str(ipage))\n",
        "    content = driver.page_source.encode('utf-8').strip()\n",
        "    soup = BeautifulSoup(content)\n",
        "    b = soup.find_all(\"div\",{\"typeof\": \"sioc:Item foaf:Document\"})\n",
        "    for i in b:\n",
        "      news_links.append(\"https://www.information.dk\"+i.find(\"a\").get(\"href\"))\n",
        "      dates.append(i.find(\"li\",\"date first\").get_text().replace(\"\\n                        \",\"\").replace(\"\\n                      \",\"\"))\n",
        "  kamus = {\"news link\":news_links, \"date\":dates}\n",
        "  df = pd.DataFrame(kamus)\n",
        "  file_name = path_output+df_link['country'][iprocess]+\" \"+str(df_link['number'][iprocess])+\" \"+df_link['link'][iprocess].replace(\"https://\",\"\").replace(\"/\",\"\").replace(\".\",\" \")+\".xlsx\"\n",
        "  df.to_excel(file_name, index=False)\n",
        "  yearList = []\n",
        "  counterList = []\n",
        "  for i in range(2023)[-6:]:\n",
        "    yearList.append(i)\n",
        "    counterList.append(years_check(i, df))\n",
        "  file_nameCek = path_output+\"result \"+df_link['country'][iprocess]+\" \"+str(df_link['number'][iprocess])+\" \"+df_link['link'][iprocess].replace(\"https://\",\"\").replace(\"/\",\"\").replace(\".\",\" \")+\".xlsx\"\n",
        "  kamusCek = {\"year\": yearList, \"Number of Related News\": counterList}\n",
        "  dfCek = pd.DataFrame(kamusCek)\n",
        "  dfCek.to_excel(file_nameCek, index=False)\n",
        "  return dfCek\n",
        "\n",
        "def denmark2politiken(keyword):\n",
        "  news_links = []\n",
        "  dates = []\n",
        "  iprocess = 1\n",
        "  for ipage in list(range(21))[1:]:\n",
        "    wd.get(\"https://politiken.dk/search/?q=keyword&target=pol&sort=pd&page=\".replace(\"keyword\",keyword)+str(ipage))\n",
        "    print(str(ipage))\n",
        "    content = driver.page_source.encode('utf-8').strip()\n",
        "    soup = BeautifulSoup(content)\n",
        "    b = soup.find_all(\"div\",\"search-result__article u-padding--vertical-normal\")\n",
        "    for i in b:\n",
        "      news_links.append(\"https://politiken.dk/\"+i.find(\"a\").get(\"href\"))\n",
        "      dates.append(i.find(\"time\").get_text().replace(\"\\n                        \",\"\").replace(\"\\n                      \",\"\"))\n",
        "  kamus = {\"news link\":news_links, \"date\":dates}\n",
        "  df = pd.DataFrame(kamus)\n",
        "  file_name = path_output+df_link['country'][iprocess]+\" \"+str(df_link['number'][iprocess])+\" \"+df_link['link'][iprocess].replace(\"https://\",\"\").replace(\"/\",\"\").replace(\".\",\" \")+\".xlsx\"\n",
        "  df.to_excel(file_name, index=False)\n",
        "  yearList = []\n",
        "  counterList = []\n",
        "  for i in range(2023)[-6:]:\n",
        "    yearList.append(i)\n",
        "    counterList.append(years_check(i, df))\n",
        "  file_nameCek = path_output+\"result \"+df_link['country'][iprocess]+\" \"+str(df_link['number'][iprocess])+\" \"+df_link['link'][iprocess].replace(\"https://\",\"\").replace(\"/\",\"\").replace(\".\",\" \")+\".xlsx\"\n",
        "  kamusCek = {\"year\": yearList, \"Number of Related News\": counterList}\n",
        "  dfCek = pd.DataFrame(kamusCek)\n",
        "  dfCek.to_excel(file_nameCek, index=False)\n",
        "  return dfCek"
      ],
      "metadata": {
        "id": "Z6Frg8H0VP4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def germany1ntv(keyword):\n",
        "  news_links = []\n",
        "  dates = []\n",
        "  iprocess = 7\n",
        "  for ipage in list(range(21))[1:]:\n",
        "    wd.get(\"https://www.n-tv.de/suche/?q=keyword&at=all&page=\".replace(\"keyword\",keyword)+str(ipage))\n",
        "    print(str(ipage))\n",
        "    content = driver.page_source.encode('utf-8').strip()\n",
        "    soup = BeautifulSoup(content)\n",
        "    b = soup.find_all(\"article\",\"teaser teaser--inline \")\n",
        "    for i in b:\n",
        "      news_links.append(\"\"+i.find(\"a\").get(\"href\"))\n",
        "      dates.append(i.find(\"span\",\"teaser__date\").get_text().replace(\"\\n                        \",\"\").replace(\"\\n                      \",\"\"))\n",
        "  kamus = {\"news link\":news_links, \"date\":dates}\n",
        "  df = pd.DataFrame(kamus)\n",
        "  file_name = path_output+df_link['country'][iprocess]+\" \"+str(df_link['number'][iprocess])+\" \"+df_link['link'][iprocess].replace(\"https://\",\"\").replace(\"/\",\"\").replace(\".\",\" \")+\".xlsx\"\n",
        "  df.to_excel(file_name, index=False)\n",
        "  yearList = []\n",
        "  counterList = []\n",
        "  for i in range(2023)[-6:]:\n",
        "    yearList.append(i)\n",
        "    counterList.append(years_check(i, df))\n",
        "  file_nameCek = path_output+\"result \"+df_link['country'][iprocess]+\" \"+str(df_link['number'][iprocess])+\" \"+df_link['link'][iprocess].replace(\"https://\",\"\").replace(\"/\",\"\").replace(\".\",\" \")+\".xlsx\"\n",
        "  kamusCek = {\"year\": yearList, \"Number of Related News\": counterList}\n",
        "  dfCek = pd.DataFrame(kamusCek)\n",
        "  dfCek.to_excel(file_nameCek, index=False)\n",
        "  return dfCek"
      ],
      "metadata": {
        "id": "7XxORmhCDHvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each time you run the function, it will give you two excel files: \n",
        "\n",
        "\n",
        "*   number of news articles found for keyword,\n",
        "*   links of news articles found with date (for cross-checks)\n",
        "\n"
      ],
      "metadata": {
        "id": "i2DTNXNFAKJ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# keywords to be searched for \n",
        "\n",
        "keyword_list = [\"gdpr\", \"dsgvo\", \"datenschutz\", \"schrems\", \"web tracking\", \"online tracking\", \"digital analytics\", \"data protection authorities\"] "
      ],
      "metadata": {
        "id": "5IfOGNTHUcXv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# denmark1information(\"gdpr\")\n",
        "# denmark2politiken(\"gdpr\")\n",
        "# germany1ntv(\"gdpr\")\n",
        "# germany3dw(\"gdpr\")\n",
        "# germany4faz(\"gdpr\")\n",
        "# germany1ntv(\"dsgvo\")\n",
        "\n",
        "for q in keyword_list:\n",
        "  germany1ntv(q)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EVMJGg_u-ocF",
        "outputId": "37cdedda-6152-4677-cdca-127873de82a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-3cd02ba0bf2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeyword_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mgermany1ntv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-19-f32344084124>\u001b[0m in \u001b[0;36mgermany1ntv\u001b[0;34m(keyword)\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2023\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0myearList\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mcounterList\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myears_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m   \u001b[0mfile_nameCek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath_output\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"result \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdf_link\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'country'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0miprocess\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_link\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'number'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0miprocess\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdf_link\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'link'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0miprocess\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".xlsx\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m   \u001b[0mkamusCek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"year\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0myearList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Number of Related News\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcounterList\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-47e82aa30c9a>\u001b[0m in \u001b[0;36myears_check\u001b[0;34m(year, df)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0myears_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mnumber_of_news_in_2022\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnumber_of_news_in_2022\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5485\u001b[0m         ):\n\u001b[1;32m   5486\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5487\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5489\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/accessor.py\u001b[0m in \u001b[0;36m__get__\u001b[0;34m(self, obj, cls)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;31m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0maccessor_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m         \u001b[0;31m# Replace the property with the accessor object. Inspired by:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;31m# https://www.pydanny.com/cached-property.html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/strings/accessor.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStringDtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inferred_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_categorical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_categorical_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStringDtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/strings/accessor.py\u001b[0m in \u001b[0;36m_validate\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minferred_dtype\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mallowed_types\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Can only use .str accessor with string values!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minferred_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: Can only use .str accessor with string values!"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZUZ88CT3AUsd"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "keyword scraper on news sites",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}